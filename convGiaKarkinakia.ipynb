{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Simple CNN model for the CIFAR-10 Dataset\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "with open('dataMelanoma.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    dataMelanoma = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_can_im_list=np.array(dataMelanoma['rescaled_can_im_list'])\n",
    "eq_can_im_list=np.array(dataMelanoma['eq_can_im_list'])\n",
    "adapteq_can_im_list=np.array(dataMelanoma['adapteq_can_im_list'])\n",
    "\n",
    "rescaled_heal_im_list=np.array(dataMelanoma['rescaled_heal_im_list'])\n",
    "eq_heal_im_list=np.array(dataMelanoma['eq_heal_im_list'])\n",
    "adapteq_heal_im_list=np.array(dataMelanoma['adapteq_heal_im_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "can_labels_train=np.ones(65)\n",
    "heal_labels_train=np.zeros(65)\n",
    "\n",
    "can_labels_pred=[1]*5\n",
    "heal_labels_pred=[0]*5\n",
    "\n",
    "\n",
    "x_train=np.concatenate((rescaled_can_im_list[:65],rescaled_heal_im_list[:65]))\n",
    "y_train=np.concatenate((can_labels_train,heal_labels_train))\n",
    "\n",
    "x_pred=np.concatenate((rescaled_can_im_list[65:70],rescaled_heal_im_list[65:70]))\n",
    "y_pred=np.concatenate((can_labels_pred,heal_labels_pred))\n",
    "print(type(y_pred))\n",
    "i=0\n",
    "for image, idd in zip(x_train, y_train):\n",
    "    i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 224, 224, 3) (130,)\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(130)\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for i in idx:\n",
    "    x_train.append(data_train[i])\n",
    "    y_train.append(classes_train[i])\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 52, 52, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,208,801\n",
      "Trainable params: 1,208,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=256, activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(x_train, y_train, validation_data=(x_pred, y_pred), epochs=30, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = classifier.evaluate(x_pred, y_pred, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130 samples, validate on 10 samples\n",
      "Epoch 1/30\n",
      "130/130 [==============================] - 7s 50ms/step - loss: 0.7816 - accuracy: 0.5077 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.6992 - accuracy: 0.5000 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.6908 - accuracy: 0.5000 - val_loss: 0.6836 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.6898 - accuracy: 0.5462 - val_loss: 0.6736 - val_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.6565 - accuracy: 0.5692 - val_loss: 0.6464 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.6829 - accuracy: 0.5538 - val_loss: 0.6543 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.6252 - accuracy: 0.7000 - val_loss: 0.6974 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.5748 - accuracy: 0.7308 - val_loss: 0.5231 - val_accuracy: 0.9000\n",
      "Epoch 9/30\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.4592 - accuracy: 0.7615 - val_loss: 0.8047 - val_accuracy: 0.8000\n",
      "Epoch 10/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.4826 - accuracy: 0.8077 - val_loss: 0.6653 - val_accuracy: 0.8000\n",
      "Epoch 11/30\n",
      "130/130 [==============================] - 6s 43ms/step - loss: 0.5058 - accuracy: 0.7769 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 12/30\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.4138 - accuracy: 0.8385 - val_loss: 0.5410 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.5259 - accuracy: 0.7462 - val_loss: 0.6028 - val_accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "130/130 [==============================] - 5s 41ms/step - loss: 0.4746 - accuracy: 0.8385 - val_loss: 0.4688 - val_accuracy: 0.7000\n",
      "Epoch 15/30\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.4188 - accuracy: 0.8385 - val_loss: 0.7902 - val_accuracy: 0.8000\n",
      "Epoch 16/30\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 0.3963 - accuracy: 0.8385 - val_loss: 0.5563 - val_accuracy: 0.8000\n",
      "Epoch 17/30\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.3697 - accuracy: 0.8462 - val_loss: 0.7406 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3591 - accuracy: 0.8462 - val_loss: 0.4356 - val_accuracy: 0.7000\n",
      "Epoch 19/30\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 0.3075 - accuracy: 0.8923 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "130/130 [==============================] - 6s 42ms/step - loss: 0.3116 - accuracy: 0.8846 - val_loss: 0.3236 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.3612 - accuracy: 0.8538 - val_loss: 0.6877 - val_accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.4518 - accuracy: 0.7615 - val_loss: 0.3564 - val_accuracy: 0.9000\n",
      "Epoch 23/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.4264 - accuracy: 0.8000 - val_loss: 0.3675 - val_accuracy: 0.8000\n",
      "Epoch 24/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.3775 - accuracy: 0.8538 - val_loss: 0.6012 - val_accuracy: 0.8000\n",
      "Epoch 25/30\n",
      "130/130 [==============================] - 5s 42ms/step - loss: 0.4142 - accuracy: 0.8077 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "130/130 [==============================] - 5s 40ms/step - loss: 0.3441 - accuracy: 0.9154 - val_loss: 0.4035 - val_accuracy: 0.7000\n",
      "Epoch 27/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.2981 - accuracy: 0.9154 - val_loss: 0.6205 - val_accuracy: 0.8000\n",
      "Epoch 28/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.2884 - accuracy: 0.8846 - val_loss: 0.2991 - val_accuracy: 0.8000\n",
      "Epoch 29/30\n",
      "130/130 [==============================] - 5s 38ms/step - loss: 0.3532 - accuracy: 0.8462 - val_loss: 0.3207 - val_accuracy: 0.7000\n",
      "Epoch 30/30\n",
      "130/130 [==============================] - 5s 39ms/step - loss: 0.4175 - accuracy: 0.8308 - val_loss: 0.3733 - val_accuracy: 0.8000\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "classifier.fit(x_train, y_train, validation_data=(x_pred, y_pred), epochs=30, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = classifier.evaluate(x_pred, y_pred, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
